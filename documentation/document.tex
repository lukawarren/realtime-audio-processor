\documentclass{article}
\usepackage{xcolor}
\usepackage{minted}

% Author info %
\title{AQA A Level Computer Science NEA}
\date{2023}
\author{Luka Warren}

% Code snippet config %
\setminted{fontsize=\footnotesize}

% For images %
\usepackage{graphicx}

% Page layout %
\usepackage[margin=1.0in]{geometry}

\begin{document}
	
	% Title page %
	\maketitle
	\pagenumbering{gobble}
	\tableofcontents
	\newpage
	\pagenumbering{arabic}
	
	
	\section{Analysis}
	
	\subsection{Background}
	There exists online many popular "remixes"  where someone has taken an existing song and distorted it, usually by adjusting its speed, bass and pitch, to achieve a desired effect. Often these versions of the song are preferred to the originals when used to accompany short-form content on video-sharing sites such as TikTok. For example,  the song "Money Trees" by Kendrick Lamar has 120 million views on YouTube  in its original form, but also a sizeable 1.6 million views on one "TikTok remix" alone, and indeed on TikTok itself it is rare to hear the original version.
	
	\paragraph{}
	As such it can be seen that there exists a large audience of people who enjoy listening to altered versions of popular songs. However, the most popular music listening programs, including Spotify and YouTube music, provide no mechanism for manually altering songs by one's self. Whilst there exists ready-made "remixes" by others, there are no mainstream programs which allow a user to "remix" a song in real-time as it is being listened to. This presents two main problems:
	
	\begin{itemize}
		\item Many songs do not have any accompanying "remixes" to satisfy a user's need
		\item The barrier to entry for creating a "remix" prevents easy and user-friendly experimentation
	\end{itemize}
	
	\paragraph{}
	It is therefore the aim of this coursework to create a system to allow users to "remix" songs in real-time as they listen to them. Such a system would allow for comprehensible, user-friendly experimentation, removing the above barrier to entry, whilst providing a mechanism to alter the sound of any arbitrary audio, removing the need to rely on other's work.
	
	\paragraph{}
	However, a system can only be comprehensible and user-friendly if the exact needs of the users themselves are known, and so first a representative sub-section of the user-base must be interviewed.
	
	\subsection{Collection of Data}
	A number of interviews were conducted with peers that self-reported to enjoy listening to song "remixes". Below is a brief summary of the questions asked and the relevant responses.
	
	\paragraph{Question 1 - Why do you sometimes prefer a song's remix?}
	\subparagraph{Student 1}
	Videos on TikTok are only about 30 seconds long. It's good to speed up a song because otherwise you couldn't enjoy the full chorus.
	\subparagraph{Student 2}
	I'm not sure really - I think I prefer it when a song has more bass than usual, and I like how distorted it sounds.
	\subparagraph{Student 3}
	I like watching remixes on YouTube because when they visualise the music it always looks very cool.
	
	\paragraph{Question 2 - How does a remix typically differ from the original song?}
	\subparagraph{Student 1}
	Usually they're faster and I guess that makes them higher-pitched too.
	\subparagraph{Student 2}
	They have more bass and are slowed down a bit. They have a bit of an echo {[effect]} too, and sometimes also they add noise to make it more relaxing. Even the volume is different.
	\subparagraph{Student 3}
	A remix usually has a different speed and is higher or lower than the original.
	
	\paragraph{Question 3 - What features would you like in a real-time audio editing program to assist in "remixing" music?}
	\subparagraph{Student 1}
	I'm not really good with editing so hopefully it would be easy to use. I'd probably only want to apply the same effect every time so there should be a way to help me with that.
	\subparagraph{Student 2}
	I'd like to be able to apply it to my entire music collection because that way all my songs could have the same effects applied. In other words I'd like to apply it to my music playlist.
	\subparagraph{Student 3}
	I think it would be cool to change the speed of songs and change the bass and treble. My car stereo can do that and it's really interesting to play with.


	\subsection{Interview Interpretation}
	\subsubsection{Frequencies}
	Through the interviews it was understood that the ability to modify certain frequency ranges was desirable, in order to affect both the bass and treble. Typically, there are two main ways of doing this:
	\begin{itemize}
		\item Applying a low-pass or high-pass filter to broadly modify the frequencies represented
		\item Modifying the incoming audio in its frequency domain using a Fourier Transform, then converting it back to the time domain using an Inverse Fourier Transform
	\end{itemize}
	Whilst applying a low or high pass filter is a very inexpensive operation, it does not provide exact control over the frequencies modified. Hence in order to best be able to manipulate frequencies, a Fourier Transform must be used.  This is not a computationally trivial task and so every effort must be made to ensure that the program created can still run fast enough to be real-time on typical high school hardware, so as not to increase the barrier of entry, as this would go against the intention of the project.
	
	\subsubsection{Playback Speed}
	The system must also be able to alter the playback speed, as this feature was highly requested. However, again this must not conflict with the real-time requirements of the system on modest high school hardware. In other words, the adjusting of playback speed should not demand a significant computational overhead (or ideally any overhead at all).
	
	\subsubsection{Other Audio Effects}
	Student 2 mentioned "remixes" often contain an "echo" or additional "noise", and so in order to avoid limiting the program to merely changing a song's speed or frequency response, it should also allow the user to apply various audio effects, including but not limited to the ones above. In order to maximise the ease of experimentation, as is desired, the effects should be easily configurable.
		
	\subsubsection{Visualisation}
	As the program is already meant to perform a Fourier Transform on the incoming audio data, it will thus already have a representation of the audio in frequency-space. Hence it would be trivial to display this data graphically so as to provide an audio visualisation feature that is, computationally, essentially free. It is hoped that by providing visual feedback to the audio as it is edited, the effects of, for example, adjusting the bass, will be easy to see and thus the processing the software is carrying out will be easy to comprehend. 
	
	\subsection{Fourier Technical Analysis}
	As mentioned above, in section 1.3.1, it is essential to use a Fourier Transform to be able to modify the incoming audio in frequency-space (for example to provide a "bass-boost"). However, the primary concern is if this algorithm can be carried out fast enough to be able to process audio in real-time.
	
	\paragraph{}
	The primary method for computing Fourier Transforms efficiently is using a Fast Fourier Transform (FFT), which is itself a subset of the Discrete Fourier Transform (DFT). DFTs operate on discrete packets of data, such as audio samples, as opposed to continuous waves, and are hence ideal for this project. Because of the various mathematical tricks used in FFTs, they reduce the time-complexity of computing DFTs from \(O(N^2)\) to \(O(N\log{N})\), providing the performance this project needs (as when dealing with large audio samples N will typically be large).
	
	\paragraph{}
	The most popular FFT algorithm is the "Cooley-Turkey" algorithm, which recursively breaks down its input into two halves. The only limitation of  this approach is that the input data size must generally be a power of two, but as the program should have control over how much data it processes at a time, this should not be an issue.
	
	\paragraph{}
	The formal definition of a DDT may look daunting:
	\[
	X_k = \sum_{n=0}^{N-1} x_n e^{-i2\pi k n/N} 
	\]
	However, a Fourier Transform is essentially just a process to convert a signal into its constituent sine waves. For example, a very basic song may be composed of a number of sine waves with low frequencies (i.e. the bass) plus many higher frequency waves that combine to form the vocals and instruments. Each frequency in an FFT has a corresponding amplitude (volume) and phase (position in time). By adjusting the amplitudes, the relative volumes of a song's frequencies can be modified at will.
	
	\paragraph{}
	It therefore appears that the issue of manipulating frequencies in the coursework should be technically possible, providing performance is maximised by using a Cooley-Turkey FFT.

	\subsection{Programming Language  and Performance Technical Analysis}
	Before embarking on a project design, an appropriate programming language must be chosen. By considering the project requirements it is apparent that two main groups of languages will likely prove insufficient.
	
	\paragraph{Interpreted Languages}
	Languages such as Python and Ruby, whilst intuitive and easy to use, may not provide sufficient CPU performance to easily allow the system to be real-time. Most music typically has two channels, each at a sample rate of around 44,000 Hz, meaning the system must process roughly 88,000 floating point numbers per second at minimum. This number can quickly grow if, for example, an echo is required, as then multiple seconds of audio may need to be considered. Whilst most machines have CPUs powerful enough to accomplish this even when under an interpreted language, it may result in high CPU usage and significant energy requirements, raising the barrier of entry to using the program. Ideally, the program should therefore not use an interpreted language, so as to maximise the number of people who can run it.
	
	\paragraph{Garbage-collected and JIT languages}
	Languages such as C\# and Java are both Just-In-Time  (JIT) compiled and garbage collected.  This is unacceptable for a real-time audio processing application as both JIT compilation and garbage collection typically introduce frequent micro-stutters, which may result in occasional blips in the program's audio, ruining the output.
	
	\paragraph{}
	After excluding the two groups of languages above, it can be seen that any language chosen must be compiled ahead-of-time to native machine code to maximise performance and avoid JIT stutter, whilst also providing direct control over memory to avoid the garbage-collection issues described above. Ideally, it should also be a modern language capable of OOP. After reviewing this requirements I have decided to use C++, as I am extremely familiar with the language and believe it suits all these requirements.

	\subsection{Data Flow Diagram}
	After considering the requirements of the project, I believe the following should serve as a good model of how data should be treated.
	
	\includegraphics[width=13cm]{DFD}

	\subsection{Final objectives}
	\begin{enumerate}
	\item  The user must be able to load a collection of audio files known as a "playlist" and then play the audio files contained within in a logical order
	\item  The user must be able to visualise the current audio being played in the frequency domain (i.e. visualise the frequencies)
	\item The user must be able to modify the audio's frequency domain (i.e. selectively modify frequencies such as by performing a bass boost) in realtime
	\item The user must be able to apply additional "audio effects" to further enhance the music: echo, volume adjustment and noise
	\item The user must be able to configure these "audio effects" individually and also apply pre-made "presets" to quickly reach a desired effect
	\item  The system must run in real-time on an average school computer
	\end{enumerate}

	\section { Design }
	\section {  Testing }
	\section {  Evaluation }

	\section { Code example }
		\begin{minted}{c++}
void EqualiserEffect::ModifySamples(std::vector<float>& samples, const float frequency) const
{
	// Perform FFT to convert to frequency domain
	FastFourierTransform fft(samples, std::nullopt);
	std::vector<std::complex<float>>& fft_output = fft.output;
	
	ModifyFrequencies(fft_output, frequency);
	
	// Perform IFFT to convert back to time domain
	InverseFourierTransform inverse(fft_output);
	std::vector<float> scaled_real_components;
	scaled_real_components.reserve(samples.size());
	for (const auto& c : inverse.output)
		scaled_real_components.emplace_back(
			c.real() / (float)inverse.output.size()
		);
	
	samples = scaled_real_components;
}
	\end{minted}
	
	
\end{document}